{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ice cream dataset - behind the scenes\n",
    "\n",
    "The purpose of this notebook is to build a toy dataset for use with the cross correlation & r-squared statistical vignette notebook. The initial temperature and precipitation data were obtained via the National Weather Service from Raleigh, NC and show a historical average from 1981 - 2010. (https://www.ncdc.noaa.gov/cdo-web/datasets#GHCND)\n",
    "\n",
    "The goal is to use these average values to generate a (pretend) year's worth of ice cream sales data.... But we might also meander through some data exploration along the way, just for fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews import opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://michw.com/DATA/NC_temp_data.csv\"\n",
    "\n",
    "# Read ice cream data into a data frame\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "# Here's a peek at the first few days of data\n",
    "df.head(3) # The first three rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove some of the less-useful columns so our dataset is easier to look at\n",
    "df = df.drop(columns=['STATION','PRCP_ATTRIBUTES','TAVG_ATTRIBUTES','TMAX_ATTRIBUTES','TMIN_ATTRIBUTES'])\n",
    "\n",
    "# Let's also convert the DATE column to the datetime format that pandas understands and uses\n",
    "df['DATE']=pd.to_datetime(df['DATE'])\n",
    "\n",
    "df.tail(3) # The last three rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also look at data type for each of the columns. \n",
    "# Note that our DATE column is in \"datetime64\" format.\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring through plots\n",
    "\n",
    "The best way to do a quick exploration of data is to plot it, so let's do that with holoviews and hvplot tools (those plotting tools allow for interactivity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot = df.hvplot.area('DATE','TMIN','TMAX',alpha=0.2,grid=True) *\\\n",
    "df.hvplot('DATE','TAVG',kind='line')\n",
    "# Adjust the appearance of the plot using holoviews\n",
    "dfplot.opts(xlabel='Date',ylabel='Air Temp (F)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making some (fake) data!\n",
    "\n",
    "The next step is to invent some data, but make it at least somewhat believable. We're going to base the dataset on a tweaked version of a simple linear function. Let's describe the underlying linear trend based on a line that intersects two specific points. \n",
    "\n",
    "The first point will be at a 40 degrees, at which point 100 ice cream cones per day will be sold. The second point will be at 70 degrees, at which point 400 cones will be sold. Below 40 degrees we'll assume an average 100 cones and above 70 we'll assume an average of 400 cones. Between the two we'll have a linear fit. \n",
    "\n",
    "The idea behind this model is that, sure, ice cream sales increase as a function of temperature, but at some point it levels off. For example, Dax is equally likely to want ice cream at 75 degrees and 100 degrees. And he's equally unlikely to want ice cream at 20 degrees or 35 degrees.\n",
    "\n",
    "Let's tackle this by making a function that is in three sections:\n",
    "\n",
    "- $<$ 40 degrees\n",
    "- between 40 and 70 degrees\n",
    "- $>$ 70 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function that generates daily cone sales for a given temperature\n",
    "def getCones(temps):\n",
    "    cones = []\n",
    "    x1,y1 = 40.,100.\n",
    "    x2,y2 = 70.,400.\n",
    "    slope = (y2-y1)/(x2-x1)\n",
    "    intercept = y1-(slope*x1)\n",
    "    #print('slope=' + str(slope) + ', intercept = ' + str(intercept))\n",
    "    for temp in temps:\n",
    "        if temp < 40:\n",
    "            cones.append(100)\n",
    "        elif (temp >= 40) & (temp<70):\n",
    "            cones.append((slope*temp)+intercept)\n",
    "        else:\n",
    "            cones.append(400)\n",
    "    return cones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in our pandas dataframe for our model of the number of cones\n",
    "# sold as a function of average temperature.\n",
    "df['conesMod'] = getCones(df.TAVG)\n",
    "\n",
    "# Plot the Cone sales data we just created.\n",
    "df.hvplot.scatter(x='TAVG',y='conesMod',grid=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot of cone sales as a function of temperature looks pretty silly. It doesn't look like real data at all. So let's add a bit of randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdev = 150\n",
    "error = [np.random.normal(val,sdev) for val in df['conesMod']]\n",
    "df['conesErr'] = df['conesMod']+error\n",
    "\n",
    "errConesPlot = df.hvplot.scatter('TAVG','conesErr',grid=True)\n",
    "errConesPlot.opts(xlabel='Date',ylabel='Air Temp (F)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, this looks a bit more believable. Tons of variation. The number of cones sold does depend on temperature, but of course it depends on loads of other stuff too. Speaking of which, let's add one more layer of quirkiness, just for fun. There's way more ice cream sold on certain days of the year. Why don't we add some outliers in manually?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('4-July-2018',350),\n",
    "        ('3-September-2018',200),\n",
    "        ('28-May-2018',250)]\n",
    "dfHolidays = pd.DataFrame(data,columns=['Date','offset'])\n",
    "dfHolidays['Date'] = pd.to_datetime(dfHolidays['Date'])\n",
    "dfHolidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in dfHolidays.iterrows:\n",
    "    row['Date']\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
